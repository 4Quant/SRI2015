<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Investigating the Microvessel Architecture of the Mouse Brain: by 4Quant</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Investigating the Microvessel Architecture of the Mouse Brain:</h1>
      <h2 class="project-tagline">An Approach for Measuring, Stitching, and Analyzing 50 Terabytes of Data</h2>
      <a href="https://github.com/4Quant/SRI2015" class="btn">View on GitHub</a>
      <a href="https://github.com/4Quant/SRI2015/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/4Quant/SRI2015/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h1>
<a id="investigating-the-microvessel-architecture-of-the-mouse-brain" class="anchor" href="#investigating-the-microvessel-architecture-of-the-mouse-brain" aria-hidden="true"><span class="octicon octicon-link"></span></a>Investigating the Microvessel Architecture of the Mouse Brain:</h1>

<h2>
<a id="an-approach-for-measuring-stitching-and-analyzing-50-terabytes-of-data" class="anchor" href="#an-approach-for-measuring-stitching-and-analyzing-50-terabytes-of-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>An Approach for Measuring, Stitching, and Analyzing 50 Terabytes of Data</h2>

<p>The presentation and related material for the SRI 2015 Conference</p>

<ul>
<li>The <a href="https://rawgit.com/4Quant/SRI2015/master/SRIPres.html">slides</a> can be seen here</li>
<li>A Demo of our <a href="https://kmader.shinyapps.io/SearchMachineDemo">Quantitative Image Search Engine</a>
</li>
</ul>

<h2>
<a id="relevant-links" class="anchor" href="#relevant-links" aria-hidden="true"><span class="octicon octicon-link"></span></a>Relevant Links</h2>

<ul>
<li><a href="http://kmader.github.io/Quantitative-Big-Imaging-2015/">Quantitative Big Imaging Course</a></li>
<li><a href="http://www.biomed.ee.ethz.ch/research/x-ray_imaging">X-Ray Imaging Group at ETH Zurich</a></li>
<li><a href="http://4quant.com/spark-summit-2014-presentation">Presentation at Spark Summit 2014</a></li>
<li><a href="http://4quant.com/spark-introduction/">Spark Introduction</a></li>
</ul>

<h2>
<a id="bio" class="anchor" href="#bio" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bio</h2>

<p>Kevin Mader is the founder of 4Quant and a lecturer in the X-ray Microscopy Group within the Department for Information Technology and Electrical Engineering at ETH Zurich. His research focuses on turning big hairy 3D images into simple, robust, reproducible numbers without resorting to black boxes or magic. In particular, as part of several collaborations, he is currently working on automatically segmenting full animal zebrafish images, characterizing rheology in 3D flows, and measuring viral infection dynamics in cell lines.</p>

<h2>
<a id="abstract" class="anchor" href="#abstract" aria-hidden="true"><span class="octicon octicon-link"></span></a>Abstract</h2>

<p>The task of processing and analyzing such large collections of measurements is exceptionally difficult. In this work, we address the challenge of stitching together terabytes worth of scans in a parallel, distributed manner. Building on the distributed frameworks of Apache Spark and Spark Imaging Layer, we have extended the methods of (S. Preibisch, Saalfeld, and Tomancak 2009) to work on these images enabling the use of many machines in parallel and drastically accelerating the speed and ease with which these large datasets can be stitched and analyzed.
By automating the acquisition, we conduct all of the scans locally in a zigzag pattern to minimize the effect of motor position drift. Each scan consists of 1000 projections sized 2560 x 2160 (14GVx) with 0.65μm isotropic voxel size. To measure the entire mouse brain approximately 15 steps will be taken in each direction (~3400 total→ 50TVx). A correlation is performed and the maximum value is taken to produce an offset vector. The entire set of positions is then updated in an iterative manner with a smoothing function applied to these vectors.</p>

<h3>
<a id="supplemental-materials" class="anchor" href="#supplemental-materials" aria-hidden="true"><span class="octicon octicon-link"></span></a>Supplemental Materials</h3>

<h4>
<a id="measurements" class="anchor" href="#measurements" aria-hidden="true"><span class="octicon octicon-link"></span></a>Measurements</h4>

<p>For the pilot study the brain sample was measured at the TOMCAT Beamline at 25keV. The scans were performed locally and consisted of 1000 projections of 2560 x 2160 resulting in a final volume of 14 GVx covering a field of view of 1.67 x 1.67 x 2.8mm with an isotropic voxel size of 650nm. The tests consisted of 60 scans of 5 x 6 x 2.</p>

<h4>
<a id="stitching" class="anchor" href="#stitching" aria-hidden="true"><span class="octicon octicon-link"></span></a>Stitching</h4>

<p>The images are stored as key-value pairs ([(x ⃗,Img),⋯]) with the key being the position of the slicee and the value being the image contents of that slice. The stitching is performed by performing comparing all of the images to all of the other images which are touching it. The keys (positions) are then updated and the process can be interated until the the image can be perfectly combined or a tolerance is reached. The results can then be stored in this format. For processing they can be reading and caching as 'views' taken from ImgLib2 (Pietzsch et al. 2012) to generate a given view or slice of the data by reading and actively stitching the components together.</p>

<h4>
<a id="citations" class="anchor" href="#citations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Citations</h4>

<ul>
<li>Pietzsch, T., S. Preibisch, P. Tomancak, and S. Saalfeld. 2012. “ImgLib2–generic image processing in Java.” Bioinformatics 28 (22): 3009–11. doi:10.1093/bioinformatics/bts543.</li>
<li>Preibisch, Stephan, Stephan Saalfeld, and Pavel Tomancak. 2009. “Globally optimal stitching of tiled 3D microscopic image acquisitions.” Bioinformatics (Oxford, England) 25 (11): 1463–5. doi:10.1093/bioinformatics/btp184</li>
</ul>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/4Quant/SRI2015">Investigating the Microvessel Architecture of the Mouse Brain:</a> is maintained by <a href="https://github.com/4Quant">4Quant</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

            <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-48764461-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>

  </body>
</html>

